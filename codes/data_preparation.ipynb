{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def entropy_spatial(sessions):\n",
    "    locations = {}\n",
    "    days = sorted(sessions.keys())\n",
    "    for d in days:\n",
    "        session = sessions[d]\n",
    "        for s in session:\n",
    "            if s[0] not in locations:\n",
    "                locations[s[0]] = 1\n",
    "            else:\n",
    "                locations[s[0]] += 1\n",
    "    frequency = np.array([locations[loc] for loc in locations])\n",
    "    frequency = frequency / np.sum(frequency)\n",
    "    entropy = - np.sum(frequency * np.log(frequency))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "class DataFoursquare(object):\n",
    "    def __init__(self, trace_min=10, global_visit=10, hour_gap=72, min_gap=10, session_min=2, session_max=10,\n",
    "                 sessions_min=2, train_split=0.7, validation_split=0.1, embedding_len=50):\n",
    "        tmp_path = \"../data/\"\n",
    "        \n",
    "        self.TWITTER_PATH = tmp_path + 'gowalla.txt'\n",
    "        self.VENUES_PATH = tmp_path + 'gowalla.txt'\n",
    "        self.SAVE_PATH = tmp_path\n",
    "        self.save_name = 'gowalla'\n",
    "\n",
    "        self.trace_len_min = trace_min\n",
    "        self.location_global_visit_min = global_visit\n",
    "        self.hour_gap = hour_gap\n",
    "        self.min_gap = min_gap\n",
    "        self.session_max = session_max\n",
    "        self.filter_short_session = session_min\n",
    "        self.sessions_count_min = sessions_min\n",
    "        self.words_embeddings_len = embedding_len\n",
    "\n",
    "        self.train_split = train_split\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.data = {}\n",
    "        self.venues = {}\n",
    "        self.words_original = []\n",
    "        self.words_lens = []\n",
    "        self.dictionary = dict()\n",
    "        self.words_dict = None\n",
    "        self.data_filter = {}\n",
    "        self.user_filter3 = None\n",
    "        self.uid_list = {}\n",
    "        self.vid_list = {'unk': [0, -1]}\n",
    "        self.vid_list_lookup = {}\n",
    "        self.vid_lookup = {}\n",
    "        self.pid_loc_lat = {}\n",
    "        self.data_neural = {}\n",
    "\n",
    "    # ############# 1. read trajectory data from twitters\n",
    "    def load_trajectory_from_tweets(self):\n",
    "        with open(self.TWITTER_PATH, encoding='latin-1') as fid:\n",
    "            for i,line in enumerate(fid):\n",
    "                uid, pid, _, _, _, _, _, tim = line.strip('\\r\\n').split('\\t')\n",
    "                if uid not in self.data:\n",
    "                    self.data[uid] = [[pid, tim]]\n",
    "                else:\n",
    "                    self.data[uid].append([pid, tim])\n",
    "                if pid not in self.venues:\n",
    "                    self.venues[pid] = 1\n",
    "                else:\n",
    "                    self.venues[pid] += 1\n",
    "                    \n",
    "    def filter_users_by_length(self):\n",
    "        uid_3 = [x for x in self.data if len(self.data[x]) > self.trace_len_min]\n",
    "        pick3 = sorted([(x, len(self.data[x])) for x in uid_3], key=lambda x: x[1], reverse=True)\n",
    "        pid_3 = [x for x in self.venues if self.venues[x] > self.location_global_visit_min]\n",
    "        pid_pic3 = sorted([(x, self.venues[x]) for x in pid_3], key=lambda x: x[1], reverse=True)\n",
    "        pid_3 = dict(pid_pic3)\n",
    "\n",
    "        session_len_list = []\n",
    "        for u in pick3:\n",
    "            uid = u[0]\n",
    "            info = self.data[uid]\n",
    "            topk = Counter([x[0] for x in info]).most_common()\n",
    "            topk1 = [x[0] for x in topk if x[1] > 1]\n",
    "            sessions = {}\n",
    "            for i, record in enumerate(info):\n",
    "                poi, tmd = record\n",
    "                try:\n",
    "                    tid = int(time.mktime(time.strptime(tmd, \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "                except Exception as e:\n",
    "                    print('error:{}'.format(e))\n",
    "                    print(tid)\n",
    "                    continue  \n",
    "                sid = len(sessions)\n",
    "                if poi not in pid_3 and poi not in topk1:\n",
    "                    # if poi not in topk1:\n",
    "                    continue\n",
    "                if i == 0 or len(sessions) == 0:\n",
    "                    sessions[sid] = [record]\n",
    "                else:\n",
    "                    if (tid - last_tid) / 3600 > self.hour_gap or len(sessions[sid - 1]) > self.session_max:\n",
    "                        sessions[sid] = [record]\n",
    "                    elif (tid - last_tid) / 60 > self.min_gap:\n",
    "                        sessions[sid - 1].append(record)\n",
    "                    else:\n",
    "                        pass\n",
    "                last_tid = tid\n",
    "            sessions_filter = {}\n",
    "            for s in sessions:\n",
    "                if len(sessions[s]) >= self.filter_short_session:\n",
    "                    sessions_filter[len(sessions_filter)] = sessions[s]\n",
    "                    session_len_list.append(len(sessions[s]))\n",
    "            if len(sessions_filter) >= self.sessions_count_min:\n",
    "                self.data_filter[uid] = {'sessions_count': len(sessions_filter), 'topk_count': len(topk), 'topk': topk,\n",
    "                                         'sessions': sessions_filter, 'raw_sessions': sessions}\n",
    "\n",
    "        self.user_filter3 = [x for x in self.data_filter if\n",
    "                             self.data_filter[x]['sessions_count'] >= self.sessions_count_min]\n",
    "        print('User Filter ', len(self.user_filter3))\n",
    "    # ########### 4. build dictionary for users and location\n",
    "    def build_users_locations_dict(self):\n",
    "        for u in self.user_filter3:\n",
    "            sessions = self.data_filter[u]['sessions']\n",
    "            if u not in self.uid_list:\n",
    "                self.uid_list[u] = [len(self.uid_list), len(sessions)]\n",
    "            for sid in sessions:\n",
    "                poi = [p[0] for p in sessions[sid]]\n",
    "                for p in poi:\n",
    "                    if p not in self.vid_list:\n",
    "                        self.vid_list_lookup[len(self.vid_list)] = p\n",
    "                        self.vid_list[p] = [len(self.vid_list), 1]\n",
    "                    else:\n",
    "                        self.vid_list[p][1] += 1\n",
    "\n",
    "    # support for radius of gyration\n",
    "    def load_venues(self):\n",
    "        with open(self.TWITTER_PATH, 'r', encoding='latin-1') as fid:\n",
    "            for line in fid:\n",
    "                uid, pid, _, _, lat, lon, _, tim = line.strip('\\r\\n').split('\\t')\n",
    "                try:\n",
    "                    self.pid_loc_lat[pid] = [float(lon), float(lat)]\n",
    "                except Exception as e:\n",
    "                    print('error:{}'.format(e))\n",
    "                    print(lon)\n",
    "                    print(lat)\n",
    "\n",
    "    def venues_lookup(self):\n",
    "        for vid in self.vid_list_lookup:\n",
    "            pid = self.vid_list_lookup[vid]\n",
    "            lon_lat = self.pid_loc_lat[pid]\n",
    "            self.vid_lookup[vid] = lon_lat\n",
    "\n",
    "    # ########## 5.0 prepare training data for neural network\n",
    "    @staticmethod\n",
    "    def tid_list(tmd):\n",
    "        tm = time.strptime(tmd, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "        tid = tm.tm_wday * 24 + tm.tm_hour\n",
    "        return tid\n",
    "\n",
    "    @staticmethod\n",
    "    def tid_list_48(tmd):\n",
    "        tm = time.strptime(tmd, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "        if tm.tm_wday in [0, 1, 2, 3, 4]:\n",
    "            tid = tm.tm_hour\n",
    "        else:\n",
    "            tid = tm.tm_hour + 24\n",
    "        return tid\n",
    "\n",
    "    def prepare_neural_data(self):\n",
    "        for u in self.uid_list:\n",
    "            sessions = self.data_filter[u]['sessions']\n",
    "            sessions_tran = {}\n",
    "            sessions_id = []\n",
    "            for sid in sessions:\n",
    "                sessions_tran[sid] = [[self.vid_list[p[0]][0], self.tid_list_48(p[1])] for p in\n",
    "                                      sessions[sid]]\n",
    "                sessions_id.append(sid)\n",
    "                \n",
    "            split_id = int(np.floor(self.train_split * len(sessions_id)))\n",
    "            split_validation = int(np.floor(self.validation_split * len(sessions_id)))\n",
    "            \n",
    "            if split_validation == 0:\n",
    "                split_validation = 1\n",
    "            \n",
    "            split_validation = split_id + split_validation\n",
    "                \n",
    "            train_id = sessions_id[:split_id]\n",
    "            validation_id = sessions_id[split_id : split_validation]\n",
    "            test_id = sessions_id[split_validation:]\n",
    "            \n",
    "            pred_len = sum([len(sessions_tran[i]) - 1 for i in train_id])\n",
    "            valid_len = sum([len(sessions_tran[i]) - 1 for i in test_id])\n",
    "            train_loc = {}\n",
    "            for i in train_id:\n",
    "                for sess in sessions_tran[i]:\n",
    "                    if sess[0] in train_loc:\n",
    "                        train_loc[sess[0]] += 1\n",
    "                    else:\n",
    "                        train_loc[sess[0]] = 1\n",
    "            # calculate entropy\n",
    "            entropy = entropy_spatial(sessions)\n",
    "\n",
    "            # calculate location ratio\n",
    "            train_location = []\n",
    "            for i in train_id:\n",
    "                train_location.extend([s[0] for s in sessions[i]])\n",
    "            train_location_set = set(train_location)\n",
    "            test_location = []\n",
    "            for i in test_id:\n",
    "                test_location.extend([s[0] for s in sessions[i]])\n",
    "            test_location_set = set(test_location)\n",
    "            whole_location = train_location_set | test_location_set\n",
    "            test_unique = whole_location - train_location_set\n",
    "            location_ratio = len(test_unique) / len(whole_location)\n",
    "\n",
    "            # calculate radius of gyration\n",
    "            lon_lat = []\n",
    "            for pid in train_location:\n",
    "                try:\n",
    "                    lon_lat.append(self.pid_loc_lat[pid])\n",
    "                except:\n",
    "                    print(pid)\n",
    "                    print('error')\n",
    "            lon_lat = np.array(lon_lat)\n",
    "            center = np.mean(lon_lat, axis=0, keepdims=True)\n",
    "            center = np.repeat(center, axis=0, repeats=len(lon_lat))\n",
    "            rg = np.sqrt(np.mean(np.sum((lon_lat - center) ** 2, axis=1, keepdims=True), axis=0))[0]\n",
    "\n",
    "            self.data_neural[self.uid_list[u][0]] = {'sessions': sessions_tran, 'train': train_id, 'test': test_id,\n",
    "                                                     'pred_len': pred_len, 'valid_len': valid_len,\n",
    "                                                     'train_loc': train_loc, 'explore': location_ratio,\n",
    "                                                     'entropy': entropy, 'rg': rg, 'validation': validation_id}\n",
    "\n",
    "    def get_parameters(self):\n",
    "        parameters = {}\n",
    "        parameters['TWITTER_PATH'] = self.TWITTER_PATH\n",
    "        parameters['SAVE_PATH'] = self.SAVE_PATH\n",
    "\n",
    "        parameters['trace_len_min'] = self.trace_len_min\n",
    "        parameters['location_global_visit_min'] = self.location_global_visit_min\n",
    "        parameters['hour_gap'] = self.hour_gap\n",
    "        parameters['min_gap'] = self.min_gap\n",
    "        parameters['session_max'] = self.session_max\n",
    "        parameters['filter_short_session'] = self.filter_short_session\n",
    "        parameters['sessions_min'] = self.sessions_count_min\n",
    "        parameters['train_split'] = self.train_split\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def save_variables(self):\n",
    "        foursquare_dataset = {'data_neural': self.data_neural, 'vid_list': self.vid_list, 'uid_list': self.uid_list,\n",
    "                              'parameters': self.get_parameters(), 'data_filter': self.data_filter,\n",
    "                              'vid_lookup': self.vid_lookup}\n",
    "        pickle.dump(foursquare_dataset, open(self.SAVE_PATH + self.save_name + '.pk', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load trajectory from ../data/brightkite.txt\n",
      "User Filter  4390\n"
     ]
    }
   ],
   "source": [
    "trace_min = 10\n",
    "global_visit = 10\n",
    "hour_gap = 72\n",
    "min_gap = 10\n",
    "session_min = 5\n",
    "session_max = 10\n",
    "sessions_min = 5\n",
    "train_split = 0.7\n",
    "validation_split = 0.1\n",
    "\n",
    "data_generator = DataFoursquare(trace_min=trace_min, global_visit=global_visit,\n",
    "                                    hour_gap=hour_gap, min_gap=min_gap,\n",
    "                                    session_min=session_min, session_max=session_max,\n",
    "                                    sessions_min=sessions_min, train_split=train_split, validation_split=validation_split)\n",
    "\n",
    "parameters = data_generator.get_parameters()\n",
    "print('load trajectory from {}'.format(data_generator.TWITTER_PATH))\n",
    "data_generator.load_trajectory_from_tweets()\n",
    "data_generator.filter_users_by_length()\n",
    "data_generator.build_users_locations_dict()\n",
    "data_generator.load_venues()\n",
    "data_generator.venues_lookup()\n",
    "data_generator.prepare_neural_data()\n",
    "data_generator.save_variables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
